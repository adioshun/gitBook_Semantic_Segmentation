# The Modern History of Object Recognition — Infographic

> 출처 : [medium](https://medium.com/@nikasa1889/the-modern-history-of-object-recognition-infographic-aea18517c318), [pdf](https://drive.google.com/file/d/0B9SNmZvpaGj1NnNsbWhTZUxYSlU/view?usp=drivesdk)

## 1. Object Recognition Research Area 

![](http://i.imgur.com/w4D29jQ.png)

## 2. History 

![](http://i.imgur.com/PXoQ353.png)

## 3. Important CNN Concepts

### 3.1 Feature 

![](http://i.imgur.com/xEUlmtH.png)
(pattern, activation of a neuron, feature detector)

A hidden neuron that is activated when a particular pattern (feature) is presented in its input region (receptive field).

The pattern that a neuron is detecting can be visualized by 
    - optimizing its input region to maximize the neuron’s activation (deep dream),
    - visualizing the gradient or guided gradient of the neuron activation on its input pixels (back propagation and guided back propagation), 
    - visualizing a set of image regions in the training dataset that activate the neuron the most
    
### 3.2 Receptive Field

![](http://i.imgur.com/btEb1LA.png)
(input region of a feature)

The region of the input image that affects the activation of a feature. 

In other words, it is the region that the feature is looking at.

Generally, a feature in a higher layer has a bigger receptive field, which allows it to learn to capture a more complex/abstract pattern. 

The ConvNet architecture determines how the receptive field change layer by layer.

### 3.3 Feature Map

![](http://i.imgur.com/wRi3zbP.png)

(a channel of a hidden layer)

A set of features that created by applying the same feature detector at different locations of an input map in a sliding window fashion (i.e. convolution). 

Features in the same feature map have the same receptive size and look for the same pattern but at different locations. 

This creates the spatial invariance properties of a ConvNet.

### 3.4 Feature Volume

![](http://i.imgur.com/8p72KhI.png)
(a hidden layer in a ConvNet)

A set of feature maps, each map searches for a particular feature at a fixed set of locations on the input map.

All features have the same receptive field size.

### 3.5 Fully connected layer as Feature Volume

![](http://i.imgur.com/oiVYeDH.png)

Fully connected layers with k hidden nodes can be seen as a $$1 \times 1 \times k$$ feature volume. 
- fc layers - usually attached to the end of a ConvNet for classification

This feature volume has one feature in each feature map, and its receptive field covers the whole image. 

The weight matrix W in an fc layer can be converted to a CNN kernel.

Convolving a kernel $$w \times h \times k$$ to a CNN feature volume $$w \times h \times d$$ creates a $$1 \times 1 \times k$$ feature volume (=FC layer with k nodes). 

Convolving a $$1 \times 1 \times k$$ filter kernel to a $$1 \times 1 \times d$$ feature volume creates a $$1 \times 1 \times k$$ feature volume. 

Replacing fully connected layers by convolution layers allows us to apply a ConvNet to an image with arbitrary size.

### 3.6 Transposed Convolution

![](http://i.imgur.com/vOEok4u.png)

(fractional strided convolution, deconvolution, upsampling)

The operation that back-propagates the gradient of a convolution operation. 
- In other words, it is the backward pass of a convolution layer. 

A transposed convolution can be implemented as a normal convolution with zero inserted between the input features. 

A convolution with filter size k, stride s and zero padding p has an associated transposed convolution with filter size k’=k, strides’=1, zero padding p’=k-p-1, and s-1 zeros inserted between each input unit.

On the left, the red input unit contributes to the activation of the 4 top left output units (through the 4 colored squares), therefore it receives gradient from these output units. 

This gradient backpropagation can be implemented by the transposed convolution shown on the right 

### 3.7 End-To-End object recognition pipeline
(end-to-end learning/system)

An object recognition pipeline that all stages (pre-processing, region proposal generation, proposal classification, post-processing) can be trained altogether by optimizing a single objective function, which is a differentiable function of all stages’ variables. 

This end-to-end pipeline is the opposite of the traditional object recognition pipeline, which connects stages in a non-differentiable fashion. 

In these systems, we do not know how changing a stage’s variable can affect the overall performance, so that each stage must be trained independently or alternately, or heuristically programmed.

## 4. Important Object Recognition Concepts

### 4.1 Bounding box proposal 

![](http://i.imgur.com/uh2oLJm.png)


(region of interest, region
proposal, box proposal)
A rectangular region of the input image that potentially
contains an object inside. These proposals can be
generated by some heuristics search: objectness,
selective search, or by a region proposal network (RPN).
A bounding box can be represented as a 4-element
vector, either storing its two corner coordinates (x0, y0,
x1, y1), or (more common) storing its center location
and its width and height (x, y, w, h). A bounding box is
usually accompanied by a confidence score of how
likely the box contains an object.
The difference between two bounding boxes is usually
measured by the L2 distance of their vector representations. w and h can be log-transformed before the
distance calculation.