# The Modern History of Object Recognition — Infographic

> 출처 : [medium](https://medium.com/@nikasa1889/the-modern-history-of-object-recognition-infographic-aea18517c318), [pdf](https://drive.google.com/file/d/0B9SNmZvpaGj1NnNsbWhTZUxYSlU/view?usp=drivesdk)

## 1. Object Recognition Research Area 

![](http://i.imgur.com/w4D29jQ.png)

## 2.

## 3. Important CNN Concepts

### 3.1 Feature 

![](http://i.imgur.com/xEUlmtH.png)
(pattern, activation of a neuron, feature detector)

A hidden neuron that is activated when a particular pattern (feature) is presented in its input region (receptive field).

The pattern that a neuron is detecting can be visualized by 
    - optimizing its input region to maximize the neuron’s activation (deep dream),
    - visualizing the gradient or guided gradient of the neuron activation on its input pixels (back propagation and guided back propagation), 
    - visualizing a set of image regions in the training dataset that activate the neuron the most
    
### 3.2 Receptive Field

![](http://i.imgur.com/btEb1LA.png)
(input region of a feature)

The region of the input image that affects the activation of a feature. 

In other words, it is the region that the feature is looking at.

Generally, a feature in a higher layer has a bigger receptive field, which allows it to learn to capture a more complex/abstract pattern. 

The ConvNet architecture determines how the receptive field change layer by layer.

### 3.3 Feature Map

![](http://i.imgur.com/wRi3zbP.png)

(a channel of a hidden layer)

A set of features that created by applying the same feature detector at different locations of an input map in a sliding window fashion (i.e. convolution). 

Features in the same feature map have the same receptive size and look for the same pattern but at different locations. 

This creates the spatial invariance properties of a ConvNet.

### 3.4 Feature Volume

![](http://i.imgur.com/8p72KhI.png)
(a hidden layer in a ConvNet)

A set of feature maps, each map searches for a particular feature at a fixed set of locations on the input map.

All features have the same receptive field size.

### 3.5 Fully connected layer as Feature Volume

![](http://i.imgur.com/oiVYeDH.png)

Fully connected layers with k hidden nodes can be seen as a $$1 \times 1 \times k$$ feature volume. 
- fc layers - usually attached to the end of a ConvNet for classification

This feature volume has one feature in each feature map, and its receptive field covers the whole image. 

The weight matrix W in an fc layer can be converted to a CNN kernel.

Convolving a kernel $$w \times h \times k$$ to a CNN feature volume $$w \times h \times d$$ creates a $$1 \times 1 \times k$$ feature volume (=FC layer with k nodes). 

Convolving a $$1 \times 1 \times k$$ filter kernel to a $$1 \times 1 \times d$$ feature volume creates a $$1 \times 1 \times k$$ feature volume. 

Replacing fully connected layers by convolution layers allows us to apply a ConvNet to an image with arbitrary size.

### 3.6 Transposed Convolution

![](http://i.imgur.com/vOEok4u.png)

(fractional strided convolution, deconvolution, upsampling)

The operation that back-propagates the gradient of a convolution operation. 
- In other words, it is the backward pass of a convolution layer. 

A transposed convolution can be implemented as a normal convolution with zero inserted between the input features. 

A convolution with filter size k, stride s and zero padding p has an associated transposed convolution with filter size k’=k, strides’=1, zero padding p’=k-p-1, and s-1 zeros inserted between each input unit.

On the left, the red input unit contributes to the activation of the 4 top left output units (through the 4 colored squares), therefore it receives gradient from these output units. 

This gradient backpropagation can be implemented by the transposed convolution shown on the right 

### 3.7 End-To-End object recognition pipeline
(end-to-end learning/system)

An object recognition pipeline that all stages (pre-processing, region proposal generation, proposal classification, post-processing) can be trained altogether by optimizing a single objective function, which is a differentiable function of all stages’ variables. 

This end-to-end pipeline is the opposite of the traditional object recognition pipeline, which connects stages in a non-differentiable fashion. 

In these systems, we do not know how changing a stage’s variable can affect the overall performance, so that each stage must be trained independently or alternately, or heuristically programmed.

## 4. Important Object Recognition Concepts

### 4.1 Bounding box proposal 

![](http://i.imgur.com/uh2oLJm.png)

(region of interest, region proposal, box proposal)

A rectangular region of the input image that potentially contains an object inside. 

These proposals can be generated by some heuristics search: 
- objectness
- selective search
- region proposal network (RPN).

A bounding box can be represented as a 4-element vector, either storing its two corner coordinates (x0, y0, x1, y1), or (more common) storing its center location and its width and height (x, y, w, h). 

A bounding box(빨간색) is usually accompanied by a confidence score of how likely the box contains an object.

The difference between two bounding boxes is usually measured by the L2 distance of their vector representations.

w and h can be log-transformed before the distance calculation.

### 4.2 Intersection over Union
(IoU, Jaccard similarity)

![](http://i.imgur.com/c3a4fdc.png)

A metric that measures the similarity between two bounding boxes = their overlapping area over their union area.

### 4.3 Non Maxium Suppression (NMS)

![](http://i.imgur.com/VyaZIsh.png)

A common algorithm to merge overlapping bounding boxes (빨간색, proposals or detections). 

Any bounding box that significantly overlaps (IoU > IoU_threshold) with a higher-confident bounding box(파란색) is suppressed (removed). 

### 4.4 Bounding box regression 

![](http://i.imgur.com/CwI8x7M.png)

(bounding box refinement)

By looking at an input region, we can infer the bounding box that better fit the object inside, even if the object is only partly visible.

The example on the right illustrates the possibility of inferring the ground truth box only by looking at part of an object. 

Therefore, one regressor can be trained to look at an input region and predict the offset ∆(x, y, w, h) between the input region box(빨간색) and the ground truth box(녹색). 

If we have one regressor for each object class, it is called class-specific regression, otherwise, it is called class-agnostic (one regressor for all classes). 

A bounding box regressor is often accompanied by a bounding box classifier (confidence scorer) to estimate the confidence of object existence in the box. 

The classifier can also be class-specific or class-agnostic. 

Without defining prior boxes, the input region box plays the role of a prior box.

### 4.5 Prior box

![](http://i.imgur.com/eDSxR80.png)

(default box, anchor box)

Instead of using the input region as the only prior box, we can train multiple bounding box regressors, each look at the same input region but has a different prior box and learns to predict the offset between its own(빨강) prior(파랑) box(노랑) and the ground truth box(녹색). 

This way, regressors with different prior boxes can learn to predict bounding boxes with different properties (aspect ratio, scale, locations). 

Prior boxes can be predefined relatively to the input region, or learned by clustering. 

An appropriate box matching strategy is crucial to make the training converge.

### 4.6 Box Matching Strategy

![](http://i.imgur.com/aQF4fpY.png)

We cannot expect a bounding box regressor to be able to predict a bounding box of an object that is too far away from its input region or its prior box (more common). 

Therefore, we need a box matching strategy to decide which prior box(파랑) is matched with a ground truth box(녹색). 

Each match is a training example for regressing. 

Possible strategies: (Multibox) matching each ground truth box with one prior box with highest IoU; (SSD, FasterRCNN) matching a prior box with any ground truth with IoU higher than 0.5.


### 4.7 Hard negative example mining

For each prior box, there is a bounding box classifier that estimates the likelihood of having an object inside. 

After box matching, all matched prior boxes are positive examples for the classifier. 

All other prior boxes are negatives. 

If we used all of these hard negative examples, there would be a significant imbalance between the positives and negatives. 

Possible solutions: pick randomly negative examples (FasterRCNN), or pick the ones that the classifier makes the most serious error (SSD), so that the ratio between the negatives and positives is at roughly 3:1.


## 5. History 

![](http://i.imgur.com/PXoQ353.png)

The modern history of object recognition goes along with the development of ConvNets, which was all started here in 2012 when AlexNet won the ILSVRC 2012 by a large margin. 

> object recognitio의 역사는 ConvNets이 발견된 2012년 부터 시작 되었다. 이때 Alexnet이 ILSVRC 2012 우승하였다. 

Note that all the object recognition approaches are orthogonal to the specific ConvNet designs (any ConvNet can be combined with any object recognition approach).

ConvNets are used as general image feature extractor


### 5.1 AlexNet 
AlexNet bases on the decades-old LeNet, combined with
data augmentation, ReLU, dropout, and GPU implementation. It proved the effectiveness of ConvNet, kicked off its
glorious comeback, and opened a new era for computer
vision.

### 5.2 RCNN

![](http://i.imgur.com/7cwjWJU.png)

Region-based ConvNet (RCNN) is a natural combination of heuristic region proposal method and ConvNet feature extractor.

From an input image, ~2000 bounding box proposals are generated using selective search. Those proposed regions are cropped and warped to a fixed-size 227x227 image. 

AlexNet is then used to extract 4096 features (fc7) for each warped image.

An SVM model is then trained to classify the object in the warped image using its 4096 features. 

Multiple class-specific bounding box regressors are also trained to refine the bounding box proposal using the 4096 extracted features.

### 5.3 OverFeat

![](http://i.imgur.com/kR9Rg7P.png)

OverFeat uses AlexNet to extract features at multiple evenly-spaced square windows in the image over multiple
scales of an input image. 

An object classifier and a class-agnostic box regressor are trained to classify object and refine bounding box for every 5x5 region in the Pool5 layer (339x339 receptive field window). 

OverFeat replaces fc layers by 1x1xn conv layers to be able to predict for multi-scale images. 

Because receptive field moves 36 pixels when moving one pixel in the Pool5, the windows are usually not well aligned with the objects. 

OverFeat introduces exhaustive pooling scheme: Pool5 is applied at every offset of its input, which results in 9 Pool5 volumes. 

The windows are now only spaced 12pixels instead of 36pixels


