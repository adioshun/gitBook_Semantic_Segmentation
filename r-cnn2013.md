|논문명|Rich feature hierarchies for accurate object detection and semantic segmentation|
|-|-|
|저자(소속)|Ross Girshick(UC Berkeley)|
|학회/년도|LSVRC 2013, [논문](https://arxiv.org/pdf/1311.2524.pdf)|
|키워드||
|참고|[발표자료](http://web.cs.ucdavis.edu/~yjlee/teaching/ecs289h-fall2014/CollinMcCarthy_RCNN.pdf), [코드_Python](https://github.com/rbgirshick/fast-rcnn)|



# R-CNN

Abstract : Our approach combines two key insights
- (1) one can apply high-capacity convolutional neural networks (CNNs) to bottom-up region proposals in order to localize and segment objects and 
- (2) when labeled training data is scarce, supervised pre-training for an auxiliary task,
followed by domain-specific fine-tuning, yields a significant performance boost.

> CNNs을 region proposal(localize and segment objects)하는데 활용 

Since we combine region proposals with CNNs, we call our method R-CNN: Regions with CNN features.
> region proposals과 CNN을 합쳤기 때문에 R-CNN이라고 이름 붙임 

We also compare R-CNN to OverFeat, a recently proposed sliding-window detector based on a similar CNN architecture
> 유사 연구인 OverFeat와도 성능 비교 실시 하였음 

## 1. Introduction

Features matter. The last decade of progress on various visual recognition tasks has been based considerably on the use of SIFT [29] and HOG [7]. But if we look at performance on the canonical visual recognition task, PASCALVOC object detection [15], it is generally acknowledged that progress has been slow during 2010-2012, with small gains obtained by building ensemble systems and employing minor variants of successful methods.
> 과거 수십년간 비젼 인식 분야는 SIFT [29] and HOG [7]를 기반으로 하였었다. 그러나 성능 향상이 느렸다. 

SIFT and HOG are blockwise orientation histograms,a representation we could associate roughly with complex cells in V1, the first cortical area in the primate visual pathway. 
But we also know that recognition occurs several stages downstream, which suggests that there might be hierarchical, multi-stage processes for computing features that are even more informative for visual recognition.
> SIFT and HOG의 특징과 새로운 통찰 : 인식은 several stages downstream에서 발생 하는것을 알고 있음. 이를 기반으로 hierarchical, multi-stage processes속성을 가진 방법을 활용함 

``` 
[역사 및 기존 연구 소개]
Fukushima’s “neocognitron” [[19]](#19), a biologically inspired hierarchical and shift-invariant model for pattern recognition, was an early attempt at just such a process.The neocognitron, however, lacked a supervised training algorithm. 

Building on Rumelhart et al. [33], LeCun etal. [26] showed that stochastic gradient descent via backpropagation was effective for training convolutional neuralnetworks (CNNs), a class of models that extend the neocognitron.

CNNs saw heavy use in the 1990s (e.g., [27]), but then fell out of fashion with the rise of support vector machines.In 2012, Krizhevsky et al. [25] rekindled interest in CNNs by showing substantially higher image classification accuracy on the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) [9, 10]. 

Their success resulted from training a large CNN on 1.2 million labeled images, together with a few twists on LeCun’s CNN (e.g., max(x; 0) rectifying non-linearities and “dropout” regularization)

The significance of the ImageNet result was vigorously debated during the ILSVRC 2012 workshop. 
The centralissue can be distilled to the following: To what extent do the CNN classification results on ImageNet generalize to object detection results on the PASCAL VOC Challenge?We answer this question by bridging the gap between image classification and object detection. 

This paper is the first to show that a CNN can lead to dramatically higher object detection performance on PASCAL VOC as compared to systems based on simpler HOG-like features. 

To achievethis result, we focused on two problems: localizing object swith a deep network and training a high-capacity modelwith only a small quantity of annotated detection data.
```
> 1980년 neocognitron연구로 hierarchical and shift-invariant model에 대하여 알게 되었으나 지도학습 알고리즘이 부족 하였다. 
> LeCun의 연구물로 backpropagation을 이용한 stochastic gradient descent이 CNN학습에 유용함을 발견 하였다. 

Unlike image classification, detection requires localizing (likely many) objects within an image. 
> 분류 문제와 다르게 탐지는 위치정보도 알아 내야 한다. 

- 리그레션 문제로 바라봄 : One approach frames localization as a regression problem. 
However, work from Szegedy et al. [38], concurrent with our own, indicates that this strategy may not fare well in practice (they report a mAP of 30.5% on VOC 2007 compared to the58.5% achieved by our method). 

- 슬라이딩 윈도우 이용 : An alternative is to build a sliding-window detector. CNNs have been used in this way for at least two decades, typically on constrained object categories, such as faces [32, 40] and pedestrians [35]. 

In order to maintain high spatial resolution, these CNNs typically only have two convolutional and pooling layers. 

We also considered adopting a sliding-window approach. 
However,units high up in our network, which has five convolutional layers, have very large receptive fields (195 × 195 pixels)and strides (32×32 pixels) in the input image, which make sprecise localization within the sliding-window paradigm an open technical challenge.

--- 
<a name="19">[19]</a> K. Fukushima. Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position. Biological cybernetics,36(4):193–202, 1980.